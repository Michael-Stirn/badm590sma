{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a Jupyter notebook that we are using for BADM590SMA. It will contain many scripts that are\n",
    "# directly from the Bonzanini textbook. His GitHub can be found at:\n",
    "# https://github.com/bonzanini/Book-SocialMediaMiningPython. His scripts will be cited here, but we (or you)\n",
    "# may modify parts of his scripts as needed.\n",
    "# You will need to pip install tweepy for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tweepy\n",
    "from tweepy import API\n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the name of the twitter handle below for the user you are investigating\n",
    "twitterhandle = 'Illinois_Alma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_twitter_auth():\n",
    "    \"\"\"Setup Twitter authentication.\n",
    "\n",
    "    Return: tweepy.OAuthHandler object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        consumer_key = os.environ['TWITTER_CONSUMER_KEY']\n",
    "        consumer_secret = os.environ['TWITTER_CONSUMER_SECRET']\n",
    "        access_token = os.environ['TWITTER_ACCESS_TOKEN']\n",
    "        access_secret = os.environ['TWITTER_ACCESS_SECRET']\n",
    "    except KeyError:\n",
    "        sys.stderr.write(\"TWITTER_* environment variables not set\\n\")\n",
    "        sys.exit(1)    \n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    return auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_twitter_client():\n",
    "    \"\"\"Setup Twitter API client.\n",
    "\n",
    "    Return: tweepy.API object\n",
    "    \"\"\"\n",
    "    auth = get_twitter_auth()\n",
    "    client = API(auth)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Getting recent tweets from a user's timeline (Rest API)\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chap02-03/twitter_get_user_timeline.py\n",
    "import sys\n",
    "import json\n",
    "from tweepy import Cursor\n",
    "\n",
    "user = twitterhandle # Change this user name to whatever you want\n",
    "client = get_twitter_client()\n",
    "\n",
    "fname = \"user_timeline_{}.jsonl\".format(user)\n",
    "with open(fname, 'w') as f:\n",
    "    for page in Cursor(client.user_timeline, screen_name=user, count=200).pages(16):\n",
    "        for status in page:\n",
    "            f.write(json.dumps(status._json)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Analyzing hastag frequencies for the user timeline pulled above\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "illini: 502\n",
      "illinois: 456\n",
      "illinoishomecoming: 70\n",
      "tbt: 35\n",
      "illinois2021: 26\n",
      "wewillwin: 25\n",
      "illinoisresearch: 24\n",
      "vetmed: 18\n",
      "illinoisfall: 17\n",
      "attheunion: 16\n",
      "crittercam: 14\n",
      "election2016: 14\n",
      "illinidays: 14\n",
      "bragginrights: 14\n",
      "chambana: 12\n",
      "illinoiswantsme: 12\n",
      "b1g: 11\n",
      "livestream: 10\n",
      "ischoolui: 10\n",
      "cancer: 9\n"
     ]
    }
   ],
   "source": [
    "# Chap02-03/twitter_hashtag_frequency.py \n",
    "import sys \n",
    "from collections import Counter \n",
    "import json \n",
    "\n",
    "user = twitterhandle # Change this user name to whatever you want\n",
    "fname = \"user_timeline_{}.jsonl\".format(user)\n",
    "\n",
    "\n",
    "def get_hashtags(tweet): \n",
    "  entities = tweet.get('entities', {}) \n",
    "  hashtags = entities.get('hashtags', []) \n",
    "  return [tag['text'].lower() for tag in hashtags]\n",
    "\n",
    "with open(fname, 'r') as f: \n",
    "    hashtags = Counter() \n",
    "    for line in f: \n",
    "        tweet = json.loads(line) \n",
    "        hashtags_in_tweet = get_hashtags(tweet) \n",
    "        hashtags.update(hashtags_in_tweet) \n",
    "    for tag, count in hashtags.most_common(20): \n",
    "        print(\"{}: {}\".format(tag, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Analyzing hastag stats for the user timeline pulled above\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1494 tweets without hashtags (46.70%)\n",
      "1705 tweets with at least one hashtag (53.30%)\n",
      "1166 tweets with 1 hashtags (36.45% total, 68.39% elite)\n",
      "422 tweets with 2 hashtags (13.19% total, 24.75% elite)\n",
      "97 tweets with 3 hashtags (3.03% total, 5.69% elite)\n",
      "15 tweets with 4 hashtags (0.47% total, 0.88% elite)\n",
      "5 tweets with 5 hashtags (0.16% total, 0.29% elite)\n"
     ]
    }
   ],
   "source": [
    "# Chap02-03/twitter_hashtag_stats.py\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "def usage():\n",
    "    print(\"Usage:\")\n",
    "    print(\"python {} <filename.jsonl>\".format(sys.argv[0]))\n",
    "\n",
    "with open(fname, 'r') as f:\n",
    "    hashtag_count = defaultdict(int)\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        hashtags_in_tweet = get_hashtags(tweet)\n",
    "        n_of_hashtags = len(hashtags_in_tweet)\n",
    "        hashtag_count[n_of_hashtags] += 1\n",
    "        \n",
    "    tweets_with_hashtags = sum([count for n_of_tags, count in hashtag_count.items() if n_of_tags > 0])\n",
    "    tweets_no_hashtags = hashtag_count[0]\n",
    "    tweets_total = tweets_no_hashtags + tweets_with_hashtags\n",
    "    tweets_with_hashtags_percent = \"%.2f\" % (tweets_with_hashtags / tweets_total * 100)\n",
    "    tweets_no_hashtags_percent = \"%.2f\" % (tweets_no_hashtags / tweets_total * 100)\n",
    "    print(\"{} tweets without hashtags ({}%)\".format(tweets_no_hashtags, tweets_no_hashtags_percent))\n",
    "    print(\"{} tweets with at least one hashtag ({}%)\".format(tweets_with_hashtags, tweets_with_hashtags_percent))\n",
    "\n",
    "    for tag_count, tweet_count in hashtag_count.items():\n",
    "        if tag_count > 0:\n",
    "            percent_total = \"%.2f\" % (tweet_count / tweets_total * 100)\n",
    "            percent_elite = \"%.2f\" % (tweet_count / tweets_with_hashtags * 100)\n",
    "            print(\"{} tweets with {} hashtags ({}% total, {}% elite)\".format(tweet_count, tag_count, percent_total, percent_elite))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Analyzing user mentions for the user timeline pulled above\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illinois_Alma: 314\n",
      "LASillinois: 133\n",
      "EngineeringAtIL: 105\n",
      "UIAA: 99\n",
      "IlliniFootball: 97\n",
      "IlliniMBB: 95\n",
      "uiucbusiness: 81\n",
      "Illini_Union: 79\n",
      "uofiadmissions: 68\n",
      "IlliniAthletics: 67\n",
      "UIarchives: 66\n",
      "edILLINOIS: 66\n",
      "ACESIllinois: 53\n",
      "VetMedIllinois: 53\n",
      "StateFarmCenter: 48\n",
      "KAMillinois: 47\n",
      "MarchingIllini: 47\n",
      "UIPD: 43\n",
      "UofIFS: 42\n",
      "IlliniVBall: 41\n"
     ]
    }
   ],
   "source": [
    "# Chap02-03/twitter_mention_frequency.py\n",
    "import sys\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "def get_mentions(tweet):\n",
    "    entities = tweet.get('entities', {})\n",
    "    hashtags = entities.get('user_mentions', [])\n",
    "    return [tag['screen_name'] for tag in hashtags]\n",
    "\n",
    "user = twitterhandle # Change this user name to whatever you want\n",
    "fname = \"user_timeline_{}.jsonl\".format(user)\n",
    "with open(fname, 'r') as f:\n",
    "    users = Counter()\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        mentions_in_tweet = get_mentions(tweet)\n",
    "        users.update(mentions_in_tweet)\n",
    "    for user, count in users.most_common(20):\n",
    "        print(\"{}: {}\".format(user, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Now let's grab the user's network (You can adjust the number of max friends)\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n"
     ]
    }
   ],
   "source": [
    "# Chap02-03/twitter_get_user.py\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "from tweepy import Cursor\n",
    "\n",
    "MAX_FRIENDS = 15000\n",
    "\n",
    "def usage():\n",
    "    print(\"Usage:\")\n",
    "    print(\"python {} <username>\".format(sys.argv[0]))\n",
    "\n",
    "def paginate(items, n):\n",
    "    \"\"\"Generate n-sized chunks from items\"\"\"\n",
    "    for i in range(0, len(items), n):\n",
    "        yield items[i:i+n]\n",
    "\n",
    "screen_name = twitterhandle\n",
    "client = get_twitter_client()\n",
    "dirname = \"users/{}\".format(screen_name)\n",
    "max_pages = math.ceil(MAX_FRIENDS / 5000)\n",
    "try:\n",
    "    os.makedirs(dirname, mode=0o755, exist_ok=True)\n",
    "except OSError:\n",
    "    print(\"Directory {} already exists\".format(dirname))\n",
    "except Exception as e:\n",
    "    print(\"Error while creating directory {}\".format(dirname))\n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "\n",
    "# get followers for a given user\n",
    "fname = \"users/{}/followers.jsonl\".format(screen_name)\n",
    "with open(fname, 'w') as f:\n",
    "    for followers in Cursor(client.followers_ids, screen_name=screen_name).pages(max_pages):\n",
    "        for chunk in paginate(followers, 100):\n",
    "            users = client.lookup_users(user_ids=chunk)\n",
    "            for user in users:\n",
    "                f.write(json.dumps(user._json)+\"\\n\")\n",
    "        if len(followers) == 5000:\n",
    "            print(\"More results available. Sleeping for 60 seconds to avoid rate limit\")\n",
    "            time.sleep(60)\n",
    "\n",
    "# get friends for a given user\n",
    "fname = \"users/{}/friends.jsonl\".format(screen_name)\n",
    "with open(fname, 'w') as f:\n",
    "    for friends in Cursor(client.friends_ids, screen_name=screen_name).pages(max_pages):\n",
    "        for chunk in paginate(friends, 100):\n",
    "            users = client.lookup_users(user_ids=chunk)\n",
    "            for user in users:\n",
    "                f.write(json.dumps(user._json)+\"\\n\")\n",
    "        if len(friends) == 5000:\n",
    "            print(\"More results available. Sleeping for 60 seconds to avoid rate limit\")\n",
    "            time.sleep(60)\n",
    "\n",
    "# get user's profile\n",
    "fname = \"users/{}/user_profile.json\".format(screen_name)\n",
    "with open(fname, 'w') as f:\n",
    "    profile = client.get_user(screen_name=screen_name)\n",
    "    f.write(json.dumps(profile._json, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wait for the above to finish as you might hit some rate limits (Check to see if the kernel is still running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Now run some following/follower stats (If you pull someone with very \n",
    "# low number of friends, then this will give you a \"Sample larger than\n",
    "# population\" error)\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Timing -----\n",
      "Initialize data: 1.2465589046478271\n",
      "Set-based operations: 5.538280010223389\n",
      "Total time: 6.784838914871216\n",
      "----- Stats -----\n",
      "Illinois_Alma has 14974 followers\n",
      "Illinois_Alma has 8527 friends\n",
      "Illinois_Alma has 366 mutual friends\n",
      "8161 friends are not following Illinois_Alma back\n",
      "14608 followers are not followed back by Illinois_Alma\n",
      "Some mutual friends: Michael_Adams1, commodityweek, NinjaYamaPT, __aphro, BrochuDanielle\n"
     ]
    }
   ],
   "source": [
    "# Chap02-03/twitter_followers_stats.py\n",
    "import sys\n",
    "import json\n",
    "from random import sample\n",
    "import time\n",
    "\n",
    "def usage():\n",
    "    print(\"Usage:\")\n",
    "    print(\"python {} <username>\".format(sys.argv[0]))\n",
    "\n",
    "followers_file = 'users/{}/followers.jsonl'.format(screen_name)\n",
    "friends_file = 'users/{}/friends.jsonl'.format(screen_name)\n",
    "with open(followers_file) as f1, open(friends_file) as f2:\n",
    "    t0 = time.time()\n",
    "    followers = []\n",
    "    friends = []\n",
    "    for line in f1:\n",
    "        profile = json.loads(line)\n",
    "        followers.append(profile['screen_name'])\n",
    "    for line in f2:\n",
    "        profile = json.loads(line)\n",
    "        friends.append(profile['screen_name'])\n",
    "    t1 = time.time()\n",
    "    mutual_friends = [user for user in friends if user in followers]\n",
    "    followers_not_following = [user for user in followers if user not in friends]\n",
    "    friends_not_following = [user for user in friends if user not in followers]\n",
    "    t2 = time.time()\n",
    "    print(\"----- Timing -----\")\n",
    "    print(\"Initialize data: {}\".format(t1-t0))\n",
    "    print(\"Set-based operations: {}\".format(t2-t1))\n",
    "    print(\"Total time: {}\".format(t2-t0))\n",
    "    print(\"----- Stats -----\")\n",
    "    print(\"{} has {} followers\".format(screen_name, len(followers)))\n",
    "    print(\"{} has {} friends\".format(screen_name, len(friends)))\n",
    "    print(\"{} has {} mutual friends\".format(screen_name, len(mutual_friends)))\n",
    "    print(\"{} friends are not following {} back\".format(len(friends_not_following), screen_name))\n",
    "    print(\"{} followers are not followed back by {}\".format(len(followers_not_following), screen_name))\n",
    "\n",
    "    some_mutual_friends = ', '.join(sample(mutual_friends, 5))\n",
    "    print(\"Some mutual friends: {}\".format(some_mutual_friends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# Let's save the content of the user's tweets to a CSV file\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "user = twitterhandle # Change this user name to whatever you want\n",
    "fname = \"user_timeline_{}.jsonl\".format(user)\n",
    "csvname = \"user_timeline_{}.csv\".format(user)\n",
    "\n",
    "tempcsv = open(csvname, 'w')\n",
    "csvwriter = csv.writer(tempcsv)\n",
    "csvwriter.writerow(['Date', 'Tweet'])\n",
    "\n",
    "with open(fname, 'r') as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        csvwriter.writerow([tweet['created_at'], tweet['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
